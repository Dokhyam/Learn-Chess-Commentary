{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "chess_train.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jVqX0F8ClYG3"
      ],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir6bRzL-hWS3"
      },
      "source": [
        "setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u1YYdC4fZDF"
      },
      "source": [
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk_QX5Fj262O"
      },
      "source": [
        "run_in_colab = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw5izra19Bqg"
      },
      "source": [
        "if run_in_colab:\n",
        "  !pip install transformers\n",
        "  !pip install wandb\n",
        "\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  \n",
        "  !git clone https://github.com/nofarmordehai/Learn-Chess-Commentary.git 'chess'\n",
        "  CODE_DIR = 'chess'\n",
        "  os.chdir(f'./{CODE_DIR}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJIGy7y9cZHa"
      },
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import time\n",
        "from Models.GPT2 import GPT2\n",
        "from Dataset.MovesDataset import MovesDataset\n",
        "from Configs.train_config import config"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goRDizAYcZHk"
      },
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j93CnZ1d9F_Y"
      },
      "source": [
        "if run_in_colab:\n",
        "  BASE_PATH = '/content/drive/MyDrive/NLP/'\n",
        "else:\n",
        "  BASE_PATH = '/home/joberant/nlp_fall_2021/nofarm/chess/'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VI0s_4NmSbN"
      },
      "source": [
        "games_data_path = BASE_PATH + 'Data/NEW_fix/games_data'\n",
        "saved_models_path = BASE_PATH + 'Models/'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVorMAYKgPKM"
      },
      "source": [
        "GPT2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ewKLGmbgWy7"
      },
      "source": [
        "gpt2 = GPT2()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCKvLLXXgeX0"
      },
      "source": [
        "gpt2.model = gpt2.model.train()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7AMjxd-h_jW"
      },
      "source": [
        "Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_EbPuQSiDOs"
      },
      "source": [
        "dataset = MovesDataset([f'{games_data_path}{i+1}.p' for i in range(config['NUMER_OF_DATA_DIRS'])], gpt2.tokenizer) "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh7s2375iGK0"
      },
      "source": [
        "train_size = int(config['train_precentege'] * len(dataset))\n",
        "test_size = len(dataset) - train_size"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKKg2VOMiHas"
      },
      "source": [
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNPlpmzLiJ5M"
      },
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NPueVq5i7d2"
      },
      "source": [
        "validation text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VAR464QjVN7"
      },
      "source": [
        "run = wandb.init(project=\"LmChess\", config={'batch size': config['batch_size'], 'lr': config['lr'], 'epochs': config['epochs']})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRQuMVr4wDKW"
      },
      "source": [
        "validation_proccessed_data, validation_attn_masks, validation_labels = next(iter(test_dataloader))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYOII4EU73_W"
      },
      "source": [
        "validation_input_encodings = []\n",
        "for i in range(config['batch_size']):\n",
        "  textual_validation_data = gpt2.tokenizer.decode(token_ids = validation_proccessed_data[i], skip_special_tokens=False).split('<comment> ')\n",
        "\n",
        "  validation_target_text = textual_validation_data[1].split(' <|endoftext|>')[0]\n",
        "  validation_input_text = textual_validation_data[0] \n",
        "\n",
        "  wandb.log({f\"validation_target_text {i}\": wandb.Html(f'<p>{validation_target_text}</p>')})\n",
        "  wandb.log({f\"validation_input_text {i}\": wandb.Html(f'<p>{validation_input_text}</p>')})\n",
        "\n",
        "  comment_idx = list(validation_proccessed_data[i]).index(dataset.comment_encoding) + 1\n",
        "  validation_input_encoding = validation_proccessed_data[0][:comment_idx].unsqueeze(0).cuda()\n",
        "  #validation_input_encoding  = gpt2.tokenizer.encode(validation_input_text, return_tensors=\"pt\").cuda()\n",
        "  \n",
        "  validation_input_encodings.append(validation_input_encoding)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHbKE9y8zUlU"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r2OySwlmIlc"
      },
      "source": [
        "optimizer = AdamW(gpt2.model.parameters(), lr= config['lr'])\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps=5000, num_training_steps=-1\n",
        ")\n",
        "loss = 0"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNcrRkmMmQcL"
      },
      "source": [
        "epochs = config['epochs']\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    with tqdm(total=len(train_dataset) / 2) as pbar:\n",
        "        for idx,entry in enumerate(train_dataloader):\n",
        "\n",
        "            if idx % 2000 == 0 and idx != 0:\n",
        "              for i in range(config['batch_size']):\n",
        "                with torch.no_grad():\n",
        "                    outputs = gpt2.model.generate(validation_input_encodings[i], num_beams=2, no_repeat_ngram_size=2, max_length=769)\n",
        "                    output_text = gpt2.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "                wandb.log({f\"output_text {i}\": wandb.Html(f'<p>{output_text}</p>')})\n",
        "            \n",
        "            if idx % 50000 == 0:\n",
        "              torch.save(gpt2.model.state_dict(), f'{saved_models_path}{idx}_{time.time()}_{int(loss)}.bin')\n",
        "\n",
        "            gpt2.model.zero_grad()\n",
        "\n",
        "            inputs = entry[0].cuda()\n",
        "            attn_masks = entry[1].cuda()\n",
        "            labels = entry[2].cuda()\n",
        "            outputs = gpt2.model(inputs, labels=labels, attention_mask = attn_masks)\n",
        "\n",
        "            loss = outputs['loss']\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            wandb.log({\"epoch\": epoch, \"loss\": loss})\n",
        "            pbar.update(2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}